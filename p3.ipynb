{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/kgHNTHngVXGjcbzaG48L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"THH7ZD2MYF9H"},"outputs":[],"source":["import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential  # Import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense  # Import necessary layers\n","import matplotlib.pyplot as plt\n","\n","# Load MNIST dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Display some sample images\n","fig = plt.figure()\n","for i in range(9):\n","    plt.subplot(3, 3, i + 1)\n","    plt.tight_layout()\n","    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n","    plt.title(\"Digit: {}\".format(y_train[i]))\n","    plt.xticks([])\n","    plt.yticks([])\n","plt.show()\n"]},{"cell_type":"code","source":["from tensorflow.keras import backend as K\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n","\n","# Assuming images are 28x28\n","img_rows, img_cols = 28, 28\n","\n","# Reshape the data according to the image data format\n","if K.image_data_format() == 'channels_first':\n","    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n","    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n","    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","# More reshaping and normalization\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","print('X_train shape:', X_train.shape) # Expected: (60000, 28, 28, 1)\n","\n","# Set number of categories\n","num_category = 10\n","\n","# Convert class vectors to binary class matrices\n","y_train = to_categorical(y_train, num_category)\n","y_test = to_categorical(y_test, num_category)\n","\n","# Model building\n","model = Sequential()\n","# Convolutional layer with ReLU activation\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n","# 64 convolution filters, each of size 3x3\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","# Choose the best features via pooling\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","# Randomly turn neurons on and off to improve convergence\n","model.add(Dropout(0.25))\n","# Flatten since too many dimensions; we only want a classification output\n","model.add(Flatten())\n","# Fully connected to get all relevant data\n","model.add(Dense(128, activation='relu'))\n","# One more dropout for convergence' sake\n","model.add(Dropout(0.5))\n","# Output a softmax to squash the matrix into output probabilities\n","model.add(Dense(num_category, activation='softmax'))\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n"],"metadata":{"id":"FYLTMEC9YUsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training parameters\n","batch_size = 128\n","num_epoch = 10\n","\n","# Model training\n","model_log = model.fit(\n","    X_train, y_train,\n","    batch_size=batch_size,\n","    epochs=num_epoch,\n","    verbose=1,\n","    validation_data=(X_test, y_test)\n",")\n","\n","# Evaluate the model\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print('Test loss:', score[0])  # Example output: Test loss: 0.0296396646054\n","print('Test accuracy:', score[1])  # Example output: Test accuracy: 0.9904\n","\n","# Plotting the metrics\n","fig = plt.figure()\n","plt.subplot(2, 1, 1)\n","plt.plot(model_log.history['accuracy'])  # Updated to 'accuracy'\n","plt.plot(model_log.history['val_accuracy'])  # Updated to 'val_accuracy'\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='lower right')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(model_log.history['loss'])\n","plt.plot(model_log.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper right')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Save the model architecture to a JSON file\n","model_digit_json = model.to_json()\n","with open(\"model_digit.json\", \"w\") as json_file:\n","    json_file.write(model_digit_json)\n","\n","# Serialize weights to HDF5\n","model.save_weights(\"model_digit.weights.h5\")  # Corrected filename\n","print(\"Saved model to disk\")\n"],"metadata":{"id":"PJJzfX-EYXs_"},"execution_count":null,"outputs":[]}]}